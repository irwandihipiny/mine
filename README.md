My research interests are (but not limited to) Computer vision, Pattern recognition, UI/UX and Animal re-ID. I also <a href="https://github.com/irwandihipiny/mine/wiki/doodles">doodles</a>.

> Interested in pursuing an Msc or a PhD? Drop me an email at mhihipni at unimas dot my

***

### Projects:
<details open> 
<summary>Design of A Deep Learning Model with Attention Mechanism for Biometric Re-identification of Green Sea Turtles in Long-term Tracking Scenario</summary>
We work with Sarawak Forestry Corp. to develop an automated biometric re-identification prototype for nesting green sea turtles. Instead of using plastic/metal tags to re-identify individuals, our solution utilises a motion-activated, downright-facing camera to capture images of nesting female sea turtles. We trained deep learning models to extract the ROIs and infer individuals' ID. We have published two articles: i. <a href="https://ijai.iaescore.com/index.php/IJAI/article/view/23748">IJAI2024</a>, in International Journal of Artificial Intelligence, 13(2), pp. 2354-2363, and ii. <a href="https://journals.uob.edu.bh/handle/123456789/5318">IJCDS2024</a>, in International Journal of Computing and Digital Systems, 16(1), pp. 201-211. Our third and final article has been accepted in Springer Nature's Scientific Data, JIF 5.8, ISSN: 2052-4463. <br><br>
<a href="https://ibb.co/4gm2CyZ"><img src="https://i.ibb.co/M52fKTD/camera-rig.jpg" alt="camera-rig" border="0" /></a>
<a href="https://ibb.co/Xp1MVcF"><img src="https://i.ibb.co/xGWd3xz/desktop.jpg" alt="desktop" border="0" /></a>
</details>
[![Demo CountPages alpha](https://media.giphy.com/media/jBOyKy9o9jlt6C3M7u/giphy.gif)]()
<br><br>

<details open> 
<summary>Who Danced Better? Ranked Dance Video Dataset and Pairwise Skill Annotation Method</summary>
We developed a pairwise skill annotation method for TikTok dance challenges. The method encodes the subject's consecutive 2D poses into string values to preserve the order and tempo (of micro movements). The article is published: <a href="https://ijain.org/index.php/IJAIN/article/view/919">IJAIN2023</a>, in International Journal of Advances in Intelligent Informatics 9(1), pp. 96-107, 2023. Dataset is available here: <a href="https://www.kaggle.com/irwandihipiny/cdrg-unimas-tiktok">link</a>. A 2nd article utilising the same dataset has also been published: <a href="https://ijai.iaescore.com/index.php/IJAI/article/view/21901">IJ-AI2023</a>, in International Journal of Artificial Intelligence 12(2), pp. 602-609, 2023. <br><br>
<a href="https://ibb.co/WWLtwq4"><img src="https://i.ibb.co/SXzr8W4/Screenshot-2021-08-06-at-4-25-55-PM.png" alt="Screenshot-2021-08-06-at-4-25-55-PM" border="0"></a>
<a href="https://ibb.co/k8YDM8z"><img src="https://i.ibb.co/bBpv7BY/Screenshot-2021-08-06-at-4-26-14-PM.png" alt="Screenshot-2021-08-06-at-4-26-14-PM" border="0"></a>
</details>
<br>

<details open> 
<summary>A Novel Keypoint-based Recognition Pipeline for Iban Mat Motifs utilising Adaptive Smoothing, a PhD student project</summary>
The first article, i.e., <a href="http://ijeecs.iaescore.com/index.php/IJEECS/article/view/25755">IJEECS2021</a>, provides evidence that we can use local feature descriptors to distinguish between classic Iban mat motif classes. Silvia's 2nd article, i.e., <a href="https://ijai.iaescore.com/index.php/IJAI/article/view/22078">IJ-AI2023</a>, introduces a classification framework that utilise adaptive smoothing to exclude small and non-discriminative features from affecting the classification results.
</details>
<br>
[![Demo CountPages alpha](https://media.giphy.com/media/rjzyfbji7ljYxRW4qY/giphy.gif)]()
<br><br>

<details open> 
<summary>AR-PHOTOBOOTH© available for purchase)</summary>
<a href="https://web.facebook.com/irwandi.hipiny.52/posts/pfbid02QopKiRPkA1cnmUChtJoRsQBb8P6f8RxtdYJs7bFaXUZdPoNvfsJZbwJxyTzwkTe5l">More details</a>,
</details>
[![Demo CountPages alpha](https://media.giphy.com/media/6jMM1SYOlnwBlyEVCC/giphy.gif)](https://web.facebook.com/irwandi.hipiny.52/posts/pfbid02QopKiRPkA1cnmUChtJoRsQBb8P6f8RxtdYJs7bFaXUZdPoNvfsJZbwJxyTzwkTe5l)
<br><br>

<details open> 
<summary>MO-LEARN©: Kinaesthetic Learning (available for purchase)</summary>
<a href="https://www.facebook.com/irwandi.hipiny.52/posts/139532623640497">More details</a>,
</details>
[![Demo CountPages alpha](https://media.giphy.com/media/kgfmemudspmq6XV0UV/giphy.gif)](https://www.facebook.com/irwandi.hipiny.52/posts/139532623640497)
<br><br>

<details open> 
<summary>MO-WALL©: Interactive Kiosk with Gesture Recognition (available for purchase)</summary>
<a href="https://www.facebook.com/irwandi.hipiny.52/posts/169078874019205">More details</a>
</details>
[![Demo CountPages alpha](https://j.gifs.com/Gv3y7Q.gif)](https://www.facebook.com/irwandi.hipiny.52/posts/169078874019205)
<br><br>

<details open> 
<summary>Biometric identification of sea turtles (Chelonia mydas)</summary>
Hipiny, I., Ujir, H., Mujahid, A., and Yahya, N.K. (2018), Towards Automated Biometric
Identification of Sea Turtles (Chelonia mydas), Journal of ICT Research and Applications, 12(3), 256-266, doi:10.5614/itbj.ict.res.appl.2018.12.3.4, <a href="http://journals.itb.ac.id/index.php/jictra/issue/view/783">Link</a>
</details>
<br>

<details open> 
<summary>Activity recognition using gaze</summary>
I worked on modeling activities as a record of fixated visual landmarks, i.e., Gaze regions (<a href="https://youtu.be/T9IAq90HNU0">See video</a>), [<a href="https://pdfs.semanticscholar.org/d19d/5c1bf21573c937165ffed0d73e57cbc03dc1.pdf">BRISTECHREPO12</a>]. The Gaze regions also prime locations of natural temporal cuts inside an egocentric video, [<a href="https://ieeexplore.ieee.org/document/8120635/">CITA15</a>], and their properties are indicative of the subject's task performance, [<a href="https://ieeexplore.ieee.org/document/7349836/">ICSIPA17a</a>]. My PhD (2014) thesis is available <a href="http://ethos.bl.uk/OrderDetails.do?uin=uk.bl.ethos.682564">here</a>.<br>
<a href="https://ibb.co/Byg06gW"><img src="https://i.ibb.co/YctHdtn/overview.png" height="80%" width="80%" alt="overview" border="0"></a>
<a href="https://ibb.co/4YNJGyy"><img src="https://i.ibb.co/txC3tff/gaze2.png" height="85%" width="85%" alt="gaze2" border="0"></a>
</details>
<br>

***

### Current Postgraduates 

| Name, Lvl           | Thesis title                                                                     | Remarks                                  |
|:--------------------|:---------------------------------------------------------------------------------|:-----------------------------------------|
| Soria S., MSc | Automatic segmentation of Region-of-Interest (ROI) in nesting Green sea turtle videos | Feb 2022 - Now, [<a href="https://journals.uob.edu.bh/handle/123456789/5318">IJCDS2024</a>] |
| Leghari I., PhD | Artificial Intelligence Approaches for Identification and Evaluation of Intellectual Disabled Down Syndrome People of Pakistan: A Model Based Study | Oct 2022 - Now, Co-sup w/ AP Dr Hamimah |
| Ghazvini A., PhD | Preserving Visual Integrity in Content-Aware Image Retargeting | Apr 2024 - Now |

***

### Graduated

| Name, Lvl           | Thesis title                                                                        | Remarks                                 |
|:--------------------|:------------------------------------------------------------------------------------|:----------------------------------------|
| Peter M., MSc       | Facial Expression Synthesis using Kernel Approach | Co-sup w/ Dr Jacey-Lynn Minoi |
| Joseph S., PhD      | Iban's Plaited Mat Motifs Recognition using Invariant Image Features | <a href="https://ir.unimas.my/id/eprint/45964/">Thesis</a>, Now at MOH Malaysia|
| Zakry K.A., MSc     | Deep Learning Model with Attention Mechanism for Biometric re-ID of Green Sea Turtles in Long-term Tracking Scenario | <a href="https://ir.unimas.my/id/eprint/46057/">Thesis</a> |

***

### Datasets
My Kaggle datasets <a href="https://www.kaggle.com/irwandihipiny/datasets">link</a>.

***

### Miscellaneous
1. [Freeglut - I use this instead of GLUT in my Computer Graphics' class](http://freeglut.sourceforge.net/)
2. [MinGW](http://mingw-w64.org/doku.php)
3. [NeHe - The best resource site for OpenGL](http://nehe.gamedev.net/)
4. [Colah's excellent LSTM tutorial](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)
5. [An excellent Youtube video on JPEG compression, DCT](https://www.youtube.com/watch?v=Q2aEzeMDHMA)
***
